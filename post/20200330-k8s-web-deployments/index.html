<!doctype html><html lang=en><head><title>Home</title><meta charset=utf-8><meta content="utf-8" http-equiv=encoding><meta name=viewport content="width=device-width,initial-scale=1"><meta name=format-detection content="telephone=no"><meta name=theme-color content="#000084"><link rel=icon href=https://angles-n-daemons.github.io/favicon.ico><link rel=canonical href=https://angles-n-daemons.github.io></head><body><nav class="navbar navbar-inverse navbar-fixed-top"><div class=navbar-inner><div class=container><button type=button class="btn btn-navbar" data-toggle=collapse data-target=.nav-collapse></button>
<a class=brand href=https://angles-n-daemons.github.io>Home</a><div class="nav-collapse collapse"><ul class=nav><li><a href=/about/><span>About</span></a></li><li><a href=/post/><span>All posts</span></a></li></ul></div></div></div></nav><div id=content class=container><div class="row-fluid navmargin"><div class=page-header><h1>Kubernetes Web Deployments, a love story - Tue, Mar 30, 2021</h1></div><p class=lead></p><p>_ Note: The names in this story are modified to as to not disclose the identity of those involved. _</p><h3 id=background>Background</h3><p>In my working history I&rsquo;ve seen some incidents that spark joy in the frightening edge cases that they illuminate. This short tale is about web deployments with kubernetes, and a lesser known evil of sending an orchestrator to do a CDN&rsquo;s job.</p><h3 id=situation>Situation</h3><p>I saw a ping one day in our engineering channel that our web deploy was stuck. Having come recently from a back end k8s shop, I quickly assured the group that although the stalled deploy had some unhealthy pods - kubernetes wouldn&rsquo;t forward traffic to a pod that didn&rsquo;t pass a healthcheck. In simpler terms - our deployment was healthy, and we didn&rsquo;t have anything to worry about because <strong>Deployment A</strong> (the previous deployment) would continue to serve most of the traffic until <strong>Deployment B</strong> (the new deployment) came up.</p><p>Crisis averted right? It would seem that way until around 10 minutes later, when my manager popped in rather frantically to say the site was down.</p><p>&ldquo;The site is down?&rdquo; I mused uncomfortably. Looking a little closer at how our services were deployed internally - it seemed like there were a few proxy layers between k8s ingress to our downstream pods and I wondered if any of these proxies could forward traffic to an unhealthy pod.</p><h3 id=root-cause-analysis>Root Cause Analysis</h3><p>By this point we had fixed the stuck deployment and the outage had ended, but I still wanted to figure out what the root of the issue was.</p><p>Soon after, I met with the platform team to iron out what had happened. They quickly debunked my strange proxy to a dead pod theory by showing me that the proxies beyond the ingress and deployment were a separate service, deployment and sidecar in a third deployment (seriously why do we do this to ourselves?) While we were speculating as to what could have gone wrong - Claire on the call pointed out a graph that caught my eye.</p><p><img src=/img/k8s-web-graph.png alt="Seeing an uptick in 404s">
<strong>Figure 1. A graph of the outage showing that web requests dropped significantly</strong></p><blockquote><p>&ldquo;Huh&mldr;we were getting about x 404s per second during this outage weren&rsquo;t we&mldr;&rdquo;</p></blockquote><p>&mldr;</p><blockquote><p>&ldquo;Well I wonder what the errors were&rdquo;</p></blockquote><p>And like that we jumped to the logs.</p><pre><code>...
1964-03-15 8:23pm [SERVICE] chasing a scooter
1964-03-15 8:23pm [SERVICE] 404 no path named /static/a.minified.js
1964-03-15 8:23pm [SERVICE] my cache way too full dog
...
</code></pre><p>And in that moment we had realized what had happened. For those who don&rsquo;t know how modern web app deployments work, there&rsquo;s generally a build step - where all the javascript gets compiled into a file (or set of files) with a unique name and is placed in some build directory. There&rsquo;s an index.html file that is also built, which references those unique build files.</p><p>Because these build names will be unique between deployments (and therefore containers) a request for index.html to Deployment A - will trigger a request for a.minified.js by the browser. If that request gets routed to a Deployment B pod the load will fail, because B will only have b.minified.js. In this way, kubernetes safe rollout behavior became an ironically fatal quirk in our deployment.</p><p><img src=/img/k8s-web-ascii.png alt="The issue with two live deployments"></p><p><strong>Figure 2. Because there was no guarantee requests would stick to pods by client, a user could request static assests from the wrong deployment</strong></p><h3 id=what-you-should-know>What you should know</h3><p>Just because the stuck deployment caused an outage, it doesn&rsquo;t mean that smooth deployments escape this behavior. On most deployments there is some period where the new deployment is scaling up and the old one is scaling down where you are likely to experience this issue. The longer the scale up period, the longer the outage window - so if you&rsquo;re thinking about deploying a web application to kubernetes think long and hard about the availability requirements and deployment frequency.</p><h4><a href=https://angles-n-daemons.github.io>Back to Home</a></h4></div></div><footer class=container><hr class=soften><p><a href=https://gitlab.com/maxlefou/hugo.386>hugo.386 theme</a> |
&copy;
<a href=http://jmf-portfolio.netlify.com target=_blank>Brian Dillmann</a>
<span id=thisyear>2020</span>
| brooklyn&rsquo;s noodle king
| Built on <a href=//gohugo.io target=_blank>Hugo</a></p><p class=text-center><a href=https://www.linkedin.com/in/brian-dillmann-0a997979/>Linkedin</a>
<a href=https://github.com/angles-n-daemons>GitHub</a></p></footer></body><link rel=stylesheet href=/css/bootstrap.css><link rel=stylesheet href=/css/bootstrap-responsive.css><link rel=stylesheet href=/css/style.css><script src=/js/jquery.js></script><script src=/js/bootstrap-386.js></script><script src=/js/bootstrap-transition.js></script><script src=/js/bootstrap-alert.js></script><script src=/js/bootstrap-modal.js></script><script src=/js/bootstrap-dropdown.js></script><script src=/js/bootstrap-scrollspy.js></script><script src=/js/bootstrap-tab.js></script><script src=/js/bootstrap-tooltip.js></script><script src=/js/bootstrap-popover.js></script><script src=/js/bootstrap-button.js></script><script src=/js/bootstrap-collapse.js></script><script src=/js/bootstrap-carousel.js></script><script src=/js/bootstrap-typeahead.js></script><script src=/js/bootstrap-affix.js></script><script>_386={fastLoad:!1,onePass:!1,speedFactor:1};function ThisYear(){document.getElementById('thisyear').innerHTML=(new Date).getFullYear()}</script></html>